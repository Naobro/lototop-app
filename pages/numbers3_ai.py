import streamlit as st
import pandas as pd
import numpy as np
from collections import defaultdict, Counter
import os
import sys
import warnings
warnings.filterwarnings("ignore")

from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier

# --- ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨æ•´å½¢ ---
CSV_PATH = "./data/n3.csv"

# æ˜ç¤ºçš„ã«å¿…è¦ãªåˆ—ã®ã¿èª­ã¿è¾¼ã‚€ï¼ˆç©ºç™½åˆ—å¯¾ç­–ï¼‰
df = pd.read_csv(CSV_PATH, usecols=[0, 1, 2, 3], names=["å›å·", "ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—"], header=0)

# ä¸å®Œå…¨ãªè¡Œã‚’é™¤å¤–ã—ã€æ•´æ•°å¤‰æ›
df = df.dropna()
df[["ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—"]] = df[["ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—"]].astype(int)

# æœ€æ–°ãƒ‡ãƒ¼ã‚¿ï¼ˆå›å·ãŒæœ€å¤§ï¼æœ€æ–°ï¼‰
df = df.sort_values("å›å·", ascending=False).reset_index(drop=True)
latest = df.iloc[0][["ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—"]].tolist()

# ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ä½œæˆ
X, y1, y2, y3 = [], [], [], []
for i in range(len(df) - 1):
    prev = df.iloc[i + 1]
    curr = df.iloc[i]
    X.append([prev["ç¬¬1æ•°å­—"], prev["ç¬¬2æ•°å­—"], prev["ç¬¬3æ•°å­—"]])
    y1.append(curr["ç¬¬1æ•°å­—"])
    y2.append(curr["ç¬¬2æ•°å­—"])
    y3.append(curr["ç¬¬3æ•°å­—"])
X = np.array(X)

# äºˆæ¸¬è£œåŠ©é–¢æ•°
def get_top3(model, x):
    probs = model.predict_proba([x])[0]
    return [i for i, _ in sorted(enumerate(probs), key=lambda x: -x[1])[:3]]

# --- Streamlitè¡¨ç¤º ---
st.title("ğŸ”¢ ãƒŠãƒ³ãƒãƒ¼ã‚º3 - AIäºˆæ¸¬ï¼ˆ3æ‰‹æ³•ï¼‰")
st.markdown("å‰å›å½“é¸ç•ªå·ï¼š<br><b style='font-size:24px; color:crimson'>{}</b>".format("-".join(map(str, latest))), unsafe_allow_html=True)

# --- 1. ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ ---
st.header("ğŸŒ² ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆäºˆæ¸¬")
rf1 = RandomForestClassifier(n_estimators=100).fit(X, y1)
rf2 = RandomForestClassifier(n_estimators=100).fit(X, y2)
rf3 = RandomForestClassifier(n_estimators=100).fit(X, y3)
rf_pred = {
    "ç¬¬1æ•°å­—": get_top3(rf1, latest),
    "ç¬¬2æ•°å­—": get_top3(rf2, latest),
    "ç¬¬3æ•°å­—": get_top3(rf3, latest)
}
st.dataframe(pd.DataFrame(rf_pred))

# --- 2. ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ ---
st.header("ğŸ§  ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯äºˆæ¸¬")
nn1 = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000).fit(X, y1)
nn2 = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000).fit(X, y2)
nn3 = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000).fit(X, y3)
nn_pred = {
    "ç¬¬1æ•°å­—": get_top3(nn1, latest),
    "ç¬¬2æ•°å­—": get_top3(nn2, latest),
    "ç¬¬3æ•°å­—": get_top3(nn3, latest)
}
st.dataframe(pd.DataFrame(nn_pred))

# --- 3. ãƒãƒ«ã‚³ãƒ•é€£é–é¢¨åˆ†æ ---
st.header("ğŸ”— ãƒãƒ«ã‚³ãƒ•é€£é–äºˆæ¸¬")

def markov_predict(column_name):
    transition = defaultdict(list)
    col = df[column_name].tolist()
    for i in range(len(col) - 1):
        transition[col[i]].append(col[i + 1])
    last = df.iloc[0][column_name]
    counter = Counter(transition[last])
    return [n for n, _ in counter.most_common(3)]

markov_pred = {
    "ç¬¬1æ•°å­—": markov_predict("ç¬¬1æ•°å­—"),
    "ç¬¬2æ•°å­—": markov_predict("ç¬¬2æ•°å­—"),
    "ç¬¬3æ•°å­—": markov_predict("ç¬¬3æ•°å­—")
}
st.dataframe(pd.DataFrame(markov_pred))

# --- é‡è¤‡æ•°å­—è¡¨ç¤º ---
st.header("âœ… 3æ‰‹æ³•ã§ä¸€è‡´ã—ãŸæ•°å­—ï¼ˆé«˜ç¢ºç‡ï¼‰")

def get_common_digits(*preds):
    result = []
    for i in ["ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—"]:
        common = set(rf_pred[i]) & set(nn_pred[i]) & set(markov_pred[i])
        result.append((i, list(common)))
    return result

common_digits = get_common_digits(rf_pred, nn_pred, markov_pred)
for label, nums in common_digits:
    st.markdown(f"**{label}**ï¼š{'ã€'.join(map(str, nums)) if nums else 'ï¼ˆä¸€è‡´ãªã—ï¼‰'}")