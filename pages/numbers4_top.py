import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import streamlit as st
from auth import check_password

check_password()
st.set_page_config(layout="centered")

import ssl
import pandas as pd
import random
import html

from collections import Counter, defaultdict
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.exceptions import NotFittedError

CSV_PATH = "https://raw.githubusercontent.com/Naobro/lototop-app/main/data/numbers4_24.csv"

def format_number(val):
    try:
        return f"{int(float(val)):,}"
    except:
        return "æœªå®šç¾©"

# æœ€æ–°è¡¨ç¤º + df_recentæŠ½å‡º + è¡¨ç¤º
def show_latest_results(csv_path):
    try:
        df = pd.read_csv(csv_path)
        df.columns = [col.replace("(", "ï¼ˆ").replace(")", "ï¼‰") for col in df.columns]
        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
        df = df.fillna("æœªå®šç¾©")
        df["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(df["æŠ½ã›ã‚“æ—¥"], errors="coerce")
        df = df.dropna(subset=["æŠ½ã›ã‚“æ—¥"])
        df = df.sort_values(by="æŠ½ã›ã‚“æ—¥", ascending=False).reset_index(drop=True)

        latest = df.iloc[0]
        global df_recent
        df_recent = df[["å›å·", "æŠ½ã›ã‚“æ—¥", "ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—", "ç¬¬4æ•°å­—"]].head(24)

        number_str = f"{latest['ç¬¬1æ•°å­—']}{latest['ç¬¬2æ•°å­—']}{latest['ç¬¬3æ•°å­—']}{latest['ç¬¬4æ•°å­—']}"

        st.header("æœ€æ–°ã®å½“é¸ç•ªå·")
        table_html = f"""
        <table style="width: 80%; margin: 0 auto; border-collapse: collapse; text-align: right;">
            <tr>
                <td style="padding: 10px; font-weight: bold;text-align: left;">å›å·</td>
                <td style="padding: 10px; font-size: 20px;">{html.escape(str(latest['å›å·']))}å›</td>
                <td style="padding: 10px; font-weight: bold;">æŠ½ã›ã‚“æ—¥</td>
                <td style="padding: 10px; font-size: 20px;">{latest['æŠ½ã›ã‚“æ—¥'].strftime('%Y-%m-%d')}</td>
            </tr>
            <tr>
                <td style="padding: 10px; font-weight: bold; text-align: left;">å½“é¸ç•ªå·</td>
                <td colspan="3" style="padding: 10px; font-size: 24px; font-weight: bold; color: red; text-align: right;">
                    {number_str}
                </td>
            </tr>
            <tr>
                <td style="padding: 10px; font-weight: bold; text-align: left;">ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆ</td>
                <td colspan="2">{format_number(latest['ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆå£æ•°'])}å£</td>
                <td>{format_number(latest['ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆå½“é¸é‡‘é¡'])}å††</td>
            </tr>
            <tr>
                <td style="padding: 10px; font-weight: bold; text-align: left;">ãƒœãƒƒã‚¯ã‚¹</td>
                <td colspan="2">{format_number(latest['ãƒœãƒƒã‚¯ã‚¹å£æ•°'])}å£</td>
                <td>{format_number(latest['ãƒœãƒƒã‚¯ã‚¹å½“é¸é‡‘é¡'])}å††</td>
            </tr>
            <tr>
                <td style="padding: 10px; font-weight: bold; text-align: left;">ã‚»ãƒƒãƒˆãƒ»ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆ</td>
                <td colspan="2">{format_number(latest['ã‚»ãƒƒãƒˆï¼ˆã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆï¼‰å£æ•°'])}å£</td>
                <td>{format_number(latest['ã‚»ãƒƒãƒˆï¼ˆã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆï¼‰å½“é¸é‡‘é¡'])}å††</td>
            </tr>
            <tr>
                <td style="padding: 10px; font-weight: bold; text-align: left;">ã‚»ãƒƒãƒˆãƒ»ãƒœãƒƒã‚¯ã‚¹</td>
                <td colspan="2">{format_number(latest['ã‚»ãƒƒãƒˆï¼ˆãƒœãƒƒã‚¯ã‚¹ï¼‰å£æ•°'])}å£</td>
                <td>{format_number(latest['ã‚»ãƒƒãƒˆï¼ˆãƒœãƒƒã‚¯ã‚¹ï¼‰å½“é¸é‡‘é¡'])}å††</td>
            </tr>
        </table>
        """
        st.markdown(table_html, unsafe_allow_html=True)

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {type(e)}")

# æœ€æ–°çµæœã¨ df_recent å®šç¾©
show_latest_results(CSV_PATH)

import pandas as pd
import streamlit as st

st.header("ç›´è¿‘24å›ã®å½“é¸ç•ªå·ï¼ˆABCåˆ†é¡ä»˜ãï¼‰")

def generate_recent_numbers4_table(csv_path):
    try:
        # CSVèª­ã¿è¾¼ã¿ã¨æ•´å½¢
        df = pd.read_csv(csv_path)
        df = df.dropna(subset=["ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—", "ç¬¬4æ•°å­—"])
        df[["ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—", "ç¬¬4æ•°å­—"]] = df[["ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—", "ç¬¬4æ•°å­—"]].astype(int)
        df["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(df["æŠ½ã›ã‚“æ—¥"], errors="coerce").dt.strftime("%Y-%m-%d")

        # ç›´è¿‘24å›ã«çµã‚‹
        df_recent = df.sort_values("å›å·", ascending=False).head(24).reset_index(drop=True)

        # ABCåˆ†é¡ãƒãƒƒãƒ—ä½œæˆï¼ˆå„æ¡ã”ã¨ï¼‰
        def get_abc_rank_map(series):
            counts = series.value_counts().sort_values(ascending=False)
            digits = counts.index.tolist()
            abc_map = {}
            for i, num in enumerate(digits[:10]):
                if i < 4:
                    abc_map[num] = "A"
                elif i < 7:
                    abc_map[num] = "B"
                else:
                    abc_map[num] = "C"
            return abc_map

        abc_map_1 = get_abc_rank_map(df_recent["ç¬¬1æ•°å­—"])
        abc_map_2 = get_abc_rank_map(df_recent["ç¬¬2æ•°å­—"])
        abc_map_3 = get_abc_rank_map(df_recent["ç¬¬3æ•°å­—"])
        abc_map_4 = get_abc_rank_map(df_recent["ç¬¬4æ•°å­—"])

        # ABCåˆ†é¡åˆ—ï¼ˆAã ã‘èµ¤æ–‡å­—ã§å¼·èª¿ï¼‰
        def abc_with_color(d1, d2, d3, d4):
            def colorize(x):
                return f'<span style="color:red;font-weight:bold">{x}</span>' if x == "A" else x
            a1 = colorize(abc_map_1.get(d1, "-"))
            a2 = colorize(abc_map_2.get(d2, "-"))
            a3 = colorize(abc_map_3.get(d3, "-"))
            a4 = colorize(abc_map_4.get(d4, "-"))
            return f"{a1},{a2},{a3},{a4}"

        df_recent["ABCåˆ†é¡"] = df_recent.apply(
            lambda row: abc_with_color(
                row["ç¬¬1æ•°å­—"], row["ç¬¬2æ•°å­—"], row["ç¬¬3æ•°å­—"], row["ç¬¬4æ•°å­—"]
            ),
            axis=1
        )

        # è¡¨ç¤ºãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆHTMLå½¢å¼ï¼‰
        df_display = df_recent[["å›å·", "æŠ½ã›ã‚“æ—¥", "ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—", "ç¬¬4æ•°å­—", "ABCåˆ†é¡"]]
        st.write(df_display.to_html(escape=False, index=False), unsafe_allow_html=True)

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# å®Ÿè¡Œ
numbers4_csv_path = "https://raw.githubusercontent.com/Naobro/lototop-app/main/data/numbers4_24.csv"
generate_recent_numbers4_table(numbers4_csv_path)
# â‘¢ å„æ¡ã®å‡ºç¾ãƒ©ãƒ³ã‚­ãƒ³ã‚°
st.header("å„æ¡ã®å‡ºç¾ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
try:
    ranking_df = pd.DataFrame({
        "é †ä½": [f"{i+1}ä½" for i in range(10)],
        "ç¬¬1æ•°å­—": df_recent["ç¬¬1æ•°å­—"].value_counts().reindex(range(10), fill_value=0).sort_values(ascending=False).index[:10],
        "ç¬¬2æ•°å­—": df_recent["ç¬¬2æ•°å­—"].value_counts().reindex(range(10), fill_value=0).sort_values(ascending=False).index[:10],
        "ç¬¬3æ•°å­—": df_recent["ç¬¬3æ•°å­—"].value_counts().reindex(range(10), fill_value=0).sort_values(ascending=False).index[:10],
        "ç¬¬4æ•°å­—": df_recent["ç¬¬4æ•°å­—"].value_counts().reindex(range(10), fill_value=0).sort_values(ascending=False).index[:10],
    })
    st.dataframe(ranking_df, use_container_width=True)
except Exception as e:
    st.error(f"ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")


import pandas as pd
import streamlit as st
from collections import Counter, defaultdict
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier

# ====================== AIäºˆæ¸¬é–¢æ•° ======================
def show_ai_predictions(csv_path):
    st.header("ğŸ¯ ãƒŠãƒ³ãƒãƒ¼ã‚º4 AIã«ã‚ˆã‚‹æ¬¡å›æ•°å­—äºˆæ¸¬")

    try:
        df = pd.read_csv(csv_path)
        st.write("âœ… CSVèª­ã¿è¾¼ã¿æˆåŠŸ")

        # ã‚«ãƒ©ãƒ æ­£è¦åŒ–
        df.columns = [col.replace('ï¼ˆ', '(').replace('ï¼‰', ')') for col in df.columns]
        required_cols = ["ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—", "ç¬¬4æ•°å­—"]
        if not all(col in df.columns for col in required_cols):
            st.error("å¿…è¦ãªã‚«ãƒ©ãƒ ï¼ˆç¬¬1æ•°å­—ã€œç¬¬4æ•°å­—ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            st.write("ç¾åœ¨ã®ã‚«ãƒ©ãƒ :", df.columns.tolist())
            return

        df = df.dropna(subset=required_cols)
        df[required_cols] = df[required_cols].astype(int)
        df = df.tail(min(len(df), 100)).reset_index(drop=True)

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        X, y1, y2, y3, y4 = [], [], [], [], []
        for i in range(len(df) - 1):
            prev = df.iloc[i + 1]
            curr = df.iloc[i]
            X.append([prev["ç¬¬1æ•°å­—"], prev["ç¬¬2æ•°å­—"], prev["ç¬¬3æ•°å­—"], prev["ç¬¬4æ•°å­—"]])
            y1.append(curr["ç¬¬1æ•°å­—"])
            y2.append(curr["ç¬¬2æ•°å­—"])
            y3.append(curr["ç¬¬3æ•°å­—"])
            y4.append(curr["ç¬¬4æ•°å­—"])

        # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆ4æ¡åˆ†ï¼‰
        rf_models = [RandomForestClassifier() for _ in range(4)]
        nn_models = [MLPClassifier(max_iter=500) for _ in range(4)]
        targets = [y1, y2, y3, y4]

        for i in range(4):
            rf_models[i].fit(X, targets[i])
            nn_models[i].fit(X, targets[i])

        latest_input = [[df.iloc[0][col] for col in ["ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—", "ç¬¬4æ•°å­—"]]]

        # TOP3æŠ½å‡ºé–¢æ•°
        def get_top3(model):
            probs = model.predict_proba(latest_input)[0]
            return sorted(range(len(probs)), key=lambda i: probs[i], reverse=True)[:3]

        # å„ãƒ¢ãƒ‡ãƒ«TOP3ï¼ˆ4æ¡åˆ†ï¼‰
        rf_top3 = [get_top3(model) for model in rf_models]
        nn_top3 = [get_top3(model) for model in nn_models]

        # ãƒãƒ«ã‚³ãƒ•é€£é– TOP3
        def markov_top3(series):
            transitions = defaultdict(Counter)
            for i in range(len(series) - 1):
                transitions[series[i]][series[i+1]] += 1
            last = series[0]
            return [num for num, _ in transitions[last].most_common(3)]

        mc_top3 = [markov_top3(df[f"ç¬¬{i+1}æ•°å­—"].tolist()) for i in range(4)]

        # è¡¨è¡¨ç¤ºé–¢æ•°ï¼ˆ4æ¡ç”¨ï¼‰
        def show_table(title, data, rows=3):
            st.subheader(title)
            df_show = pd.DataFrame({
                "ç¬¬1æ•°å­—": data[0][:rows],
                "ç¬¬2æ•°å­—": data[1][:rows],
                "ç¬¬3æ•°å­—": data[2][:rows],
                "ç¬¬4æ•°å­—": data[3][:rows]
            })
            df_show.index = [f"{i+1}ç•ªç›®" for i in range(rows)]
            st.dataframe(df_show.style.set_properties(**{'text-align': 'center'}), use_container_width=True)

        # ãƒ¢ãƒ‡ãƒ«åˆ¥è¡¨ç¤º
        show_table("ğŸŒ² ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ TOP3", rf_top3)
        show_table("ğŸ§  ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ TOP3", nn_top3)
        show_table("ğŸ” ãƒãƒ«ã‚³ãƒ•é€£é– TOP3", mc_top3)

        # çµ±åˆ â†’ TOP5
        final_top5 = []
        for i in range(4):
            combined = rf_top3[i] + nn_top3[i] + mc_top3[i]
            freq = Counter(combined)
            top5 = [num for num, _ in freq.most_common()]
            final_top5.append(sorted(set(top5))[:5])

        # çµ±åˆTOP5è¡¨ç¤º
        show_table("âœ… 3ãƒ¢ãƒ‡ãƒ«çµ±åˆ TOP5", final_top5, rows=5)

    except Exception as e:
        st.error("AIäºˆæ¸¬ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        st.exception(e)

# ====================== å‘¼ã³å‡ºã— ======================
def show_page():
    show_ai_predictions("data/n4.csv")

show_page()







def show_ai_predictions_n4(csv_path):
    try:
        # CSVèª­ã¿è¾¼ã¿ã¨æ•´å½¢
        df = pd.read_csv(csv_path)
        df = df.loc[
            df["ç¬¬1æ•°å­—"].notnull() &
            df["ç¬¬2æ•°å­—"].notnull() &
            df["ç¬¬3æ•°å­—"].notnull() &
            df["ç¬¬4æ•°å­—"].notnull()
        ]
        df = df.dropna(subset=["ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—", "ç¬¬4æ•°å­—"])
        df[["ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—", "ç¬¬4æ•°å­—"]] = df[["ç¬¬1æ•°å­—", "ç¬¬2æ•°å­—", "ç¬¬3æ•°å­—", "ç¬¬4æ•°å­—"]].astype(int)
        
        # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®ç›´å¾Œã‚’äºˆæ¸¬å¯¾è±¡ã¨ã™ã‚‹
        latest = [int(df.iloc[0][f"ç¬¬{i}æ•°å­—"]) for i in range(1, 5)]

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ­£è§£ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆ
        X = []
        y = {i: [] for i in range(1, 5)}
        for i in range(len(df) - 1):
            row = [int(df.iloc[i][f"ç¬¬{j}æ•°å­—"]) for j in range(1, 5)]
            next_row = [int(df.iloc[i + 1][f"ç¬¬{j}æ•°å­—"]) for j in range(1, 5)]
            X.append(row)
            for j in range(1, 5):
                y[j].append(next_row[j - 1])

        # ãƒ¢ãƒ‡ãƒ«å®šç¾©
        rf_models = {i: RandomForestClassifier() for i in range(1, 5)}
        nn_models = {i: MLPClassifier(max_iter=1000, random_state=42) for i in range(1, 5)}

        # å­¦ç¿’
        for i in range(1, 5):
            rf_models[i].fit(X, y[i])
            nn_models[i].fit(X, y[i])

        # äºˆæ¸¬ï¼ˆå‡ºåŠ›ã‚’intã§æ•´å½¢ï¼‰
        rf_pred = [int(rf_models[i].predict([latest])[0]) for i in range(1, 5)]
        nn_pred = [int(nn_models[i].predict([latest])[0]) for i in range(1, 5)]

        # ãƒãƒ«ã‚³ãƒ•é€£é–çš„äºˆæ¸¬ï¼ˆæœ€é »å€¤ï¼‰
        next_numbers = list(zip(*X))[0]
        mc_pred = []
        for i in range(1, 5):
            nexts = []
            for j in range(len(X)):
                if X[j] == latest:
                    nexts.append(y[i][j])
            if nexts:
                mc_pred.append(Counter(nexts).most_common(1)[0][0])
            else:
                mc_pred.append(random.choice(range(10)))  # fallback

                # è¡¨ç¤ºï¼šå„ãƒ¢ãƒ‡ãƒ«ã§ã®ä¸Šä½3å€™è£œã‚’å–å¾—
        def get_top3(model_dict, X, y):
            top3 = []
            for i in range(1, 5):
                probas = model_dict[i].predict_proba([latest])[0]
                top_indices = probas.argsort()[-3:][::-1]
                top3.append(", ".join(str(idx) for idx in top_indices))
            return top3

        rf_top3 = get_top3(rf_models, X, y)
        nn_top3 = get_top3(nn_models, X, y)

        # ãƒãƒ«ã‚³ãƒ•é€£é–ã®ä¸Šä½3å€™è£œï¼ˆå‡ºç¾é »åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
        mc_top3 = []
        for i in range(1, 5):
            nexts = []
            for j in range(len(X)):
                if X[j] == latest:
                    nexts.append(y[i][j])
            if nexts:
                freq = Counter(nexts).most_common(3)
                mc_top3.append(", ".join(str(x[0]) for x in freq))
            else:
                mc_top3.append(", ".join(str(random.randint(0, 9)) for _ in range(3)))

        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        result_df = pd.DataFrame([
            ["ğŸŒ² ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ"] + rf_top3,
            ["ğŸ§  ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ"] + nn_top3,
            ["ğŸ” ãƒãƒ«ã‚³ãƒ•é€£é–"] + mc_top3
        ], columns=["ãƒ¢ãƒ‡ãƒ«å", "ç¬¬1æ•°å­—å€™è£œ", "ç¬¬2æ•°å­—å€™è£œ", "ç¬¬3æ•°å­—å€™è£œ", "ç¬¬4æ•°å­—å€™è£œ"])

        st.subheader("ğŸ” AIãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ï¼ˆæ¬¡ã«æ¥ã‚‹æ•°å­—ã®ä¸Šä½3å€™è£œï¼‰")
        st.dataframe(result_df, use_container_width=True)
    except Exception as e:
        st.error("AIäºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        st.error(str(e))

st.header("AIã«ã‚ˆã‚‹æ¬¡å›æ•°å­—äºˆæ¸¬ï¼ˆãƒŠãƒ³ãƒãƒ¼ã‚º4ï¼‰")
show_ai_predictions_n4("https://raw.githubusercontent.com/Naobro/lototop-app/main/data/n4.csv")

# â‘£ W/S/T ã‚«ã‚¦ãƒ³ãƒˆ
st.subheader("ã‚·ãƒ³ã‚°ãƒ«ãƒ»ãƒ€ãƒ–ãƒ«ãƒ»ãƒˆãƒªãƒ—ãƒ«åˆ†æ")
s = d = t = 0
for _, row in df_recent.iterrows():
    cnts = Counter([row[f"ç¬¬{i}æ•°å­—"] for i in range(1, 5)])
    vals = list(cnts.values())
    if 3 in vals:
        t += 1
    elif vals.count(2) == 1:
        d += 1
    else:
        s += 1
st.write(pd.DataFrame({
    "ã‚¿ã‚¤ãƒ—": ["ã‚·ãƒ³ã‚°ãƒ«", "ãƒ€ãƒ–ãƒ«", "ãƒˆãƒªãƒ—ãƒ«"],
    "å›æ•°": [s, d, t]
}))

# â‘¤ ã²ã£ã±ã‚Šæ•°å­—
st.subheader("ã²ã£ã±ã‚Šæ•°å­—ã®å›æ•°")
hoppari = 0
for i in range(1, len(df_recent)):
    prev = set(df_recent.iloc[i - 1][[f"ç¬¬{n}æ•°å­—" for n in range(1, 5)]])
    curr = set(df_recent.iloc[i][[f"ç¬¬{n}æ•°å­—" for n in range(1, 5)]])
    if prev & curr:
        hoppari += 1
st.write(f"ã²ã£ã±ã‚Šæ•°å­—ã®å›æ•°ï¼š{hoppari} å›")
# â‘¥ æ•°å­—ã®ç¯„å›²åˆ†å¸ƒ
st.subheader("â‘¥ æ•°å­—ã®ç¯„å›²ã”ã¨ã®åˆ†å¸ƒ")
range_counts = {'0-2': 0, '3-5': 0, '6-9': 0}
for _, row in df_recent.iterrows():
    for i in range(1, 5):
        num = row[f"ç¬¬{i}æ•°å­—"]
        if num <= 2:
            range_counts['0-2'] += 1
        elif num <= 5:
            range_counts['3-5'] += 1
        else:
            range_counts['6-9'] += 1
st.write(pd.DataFrame({
    "ç¯„å›²": list(range_counts.keys()),
    "å‡ºç¾å›æ•°": list(range_counts.values())
}))

# â‘¦ ãƒšã‚¢åˆ†æ
st.subheader("ãƒšã‚¢ï¼ˆ2ã¤çµ„ï¼‰å‡ºç¾å›æ•°")
pair_counts = Counter()
for _, row in df_recent.iterrows():
    nums = [row[f"ç¬¬{i}æ•°å­—"] for i in range(1, 5)]
    for i in range(4):
        for j in range(i+1, 4):
            pair = tuple(sorted([nums[i], nums[j]]))
            pair_counts[pair] += 1
pair_df = pd.DataFrame(pair_counts.items(), columns=["ãƒšã‚¢", "å‡ºç¾å›æ•°"]).sort_values(by="å‡ºç¾å›æ•°", ascending=False)
st.dataframe(pair_df)

# â‘§ åˆè¨ˆå€¤åˆ†æ
st.subheader("åˆè¨ˆå€¤ã®å‡ºç¾å›æ•°")
sum_counts = Counter()
for _, row in df_recent.iterrows():
    total = sum([row[f"ç¬¬{i}æ•°å­—"] for i in range(1, 5)])
    sum_counts[total] += 1
sum_df = pd.DataFrame(sum_counts.items(), columns=["åˆè¨ˆå€¤", "å‡ºç¾å›æ•°"]).sort_values(by="å‡ºç¾å›æ•°", ascending=False)
st.dataframe(sum_df)

# â‘ª ã‚¹ã‚­ãƒƒãƒ—å›æ•°åˆ†æï¼ˆæ•°å­—ã”ã¨ã«ç›´è¿‘3å›ã®å‡ºç¾ä½ç½®ã‚’ã€Œâ—¯å›å‰ã€ã§è¡¨ç¤ºï¼‰
st.subheader("ã‚¹ã‚­ãƒƒãƒ—å›æ•°åˆ†æï¼ˆæ•°å­—ã”ã¨ã«ç›´è¿‘3å›ã®å‡ºç¾ï¼šâ—¯å›å‰ï¼‰")

try:
    # å„æ•°å­—ã®å‡ºç¾ä½ç½®ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰ã‚’è¨˜éŒ²ï¼ˆ0ãŒæœ€æ–°ï¼‰
    history_map = {i: [] for i in range(10)}

    for idx in range(len(df_recent)):
        row = df_recent.iloc[idx]
        for d in range(1, 5):
            num = row[f"ç¬¬{d}æ•°å­—"]
            if idx not in history_map[num]:
                history_map[num].append(idx)

    # è¡¨ç¤ºç”¨ã«ã€Œâ—¯å›å‰ã€å½¢å¼ã«å¤‰æ›ï¼ˆãªã‘ã‚Œã°ã€Œå‡ºç¾ãªã—ã€ï¼‰
    def format_rank(n):
        return f"{n}å›å‰" if isinstance(n, int) else "å‡ºç¾ãªã—"

    display_rows = []
    for num in range(10):
        last_1 = format_rank(history_map[num][0]) if len(history_map[num]) > 0 else "å‡ºç¾ãªã—"
        last_2 = format_rank(history_map[num][1]) if len(history_map[num]) > 1 else "å‡ºç¾ãªã—"
        last_3 = format_rank(history_map[num][2]) if len(history_map[num]) > 2 else "å‡ºç¾ãªã—"
        display_rows.append({
            "æ•°å­—": num,
            "ç›´è¿‘å‡ºç¾": last_1,
            "2å›å‰å‡ºç¾": last_2,
            "3å›å‰å‡ºç¾": last_3
        })

    skip_df = pd.DataFrame(display_rows)
    st.dataframe(skip_df)

except Exception as e:
    st.error(f"ã‚¹ã‚­ãƒƒãƒ—åˆ†æã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# â‘¨ è»¸æ•°å­—ã‹ã‚‰äºˆæƒ³
st.header("â‘¨ ãƒŠãƒ³ãƒãƒ¼ã‚º4äºˆæƒ³ï¼ˆè»¸æ•°å­—æŒ‡å®šï¼‰")
axis = st.selectbox("è»¸æ•°å­—ã‚’é¸ã‚“ã§ãã ã•ã„ï¼ˆ0ã€œ9ï¼‰", list(range(10)))
if st.button("20é€šã‚Šã‚’è¡¨ç¤º"):
    preds = []
    while len(preds) < 20:
        others = random.sample([i for i in range(10) if i != axis], 3)
        combo = sorted([axis] + others)
        if combo not in preds:
            preds.append(combo)
    st.dataframe(pd.DataFrame(preds, columns=["äºˆæ¸¬1", "äºˆæ¸¬2", "äºˆæ¸¬3", "äºˆæ¸¬4"]))

# â‘© é«˜åº¦äºˆæƒ³ï¼šåˆè¨ˆå€¤ãƒ»ã‚¹ã‚­ãƒƒãƒ—ãƒ»ABCãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®
st.header("ãƒŠãƒ³ãƒãƒ¼ã‚º4äºˆæƒ³ï¼ˆAIé¢¨ãƒ­ã‚¸ãƒƒã‚¯ï¼‰")

if st.button("AIé¢¨ãƒ­ã‚¸ãƒƒã‚¯ã§20é€šã‚Šç”Ÿæˆ"):
    # åˆè¨ˆå€¤ã®å¹³å‡ãƒ»ä¸­å¤®å€¤ãƒ»ãƒ¢ãƒ¼ãƒ‰ã‚’å–å¾—
    total_sums = df_recent[[f"ç¬¬{i}æ•°å­—" for i in range(1, 5)]].sum(axis=1)
    avg = total_sums.mean()
    med = total_sums.median()
    mode_vals = total_sums.mode().tolist()

    # ã‚¹ã‚­ãƒƒãƒ—å›æ•°ï¼ˆæœ€å¾Œã«å‡ºã¦ã‹ã‚‰ä½•å›å‡ºã¦ã„ãªã„ã‹ï¼‰
    recent_flat = []
    for _, row in df_recent.iterrows():
        recent_flat.extend([row[f"ç¬¬{i}æ•°å­—"] for i in range(1, 5)])
    skip_count = {i: None for i in range(10)}
    for idx in range(len(df_recent)):
        row = df_recent.iloc[idx]
        for d in range(1, 5):
            num = row[f"ç¬¬{d}æ•°å­—"]
            if skip_count[num] is None:
                skip_count[num] = idx

    # ABCåˆ†é¡é–¢æ•°
    def classify_abc(n):
        if n <= 3:
            return "A"
        elif n <= 6:
            return "B"
        else:
            return "C"

    # äºˆæƒ³ç”Ÿæˆ
    def is_valid_combo(combo):
        total = sum(combo)
        if not (med - 4 <= total <= med + 4):  # åˆè¨ˆå€¤ã‚’ä¸­å¤®å€¤Â±4ä»¥å†…ã«åˆ¶é™
            return False
        abc_counts = {"A": 0, "B": 0, "C": 0}
        for n in combo:
            abc_counts[classify_abc(n)] += 1
        if max(abc_counts.values()) >= 3:  # ABCãŒ1ç¨®é¡ã«åã‚Šã™ãã¦ã„ã‚Œã°NG
            return False
        if all(skip_count[n] is not None and skip_count[n] < 3 for n in combo):
            return False  # å…¨éƒ¨æœ€è¿‘å‡ºã¦ã„ã‚‹æ•°å­—ã ã‘ â†’ NG
        return True

    predictions = []
    tries = 0
    while len(predictions) < 20 and tries < 1000:
        cand = sorted(random.sample(range(10), 4))
        if cand not in predictions and is_valid_combo(cand):
            predictions.append(cand)
        tries += 1

    if predictions:
        st.success("ä»¥ä¸‹ã®æ¡ä»¶ã§çµã‚Šè¾¼ã¾ã‚ŒãŸäºˆæƒ³ã‚’è¡¨ç¤ºã—ã¾ã™ï¼š")
        st.markdown("- åˆè¨ˆå€¤ï¼šä¸­å¤®å€¤ Â±4")
        st.markdown("- ABCãƒãƒ©ãƒ³ã‚¹ï¼ˆåã‚Šã™ãNGï¼‰")
        st.markdown("- æœ€è¿‘å‡ºã¦ã„ãªã„æ•°å­—ã‚’å„ªå…ˆ")
        st.dataframe(pd.DataFrame(predictions, columns=["äºˆæ¸¬1", "äºˆæ¸¬2", "äºˆæ¸¬3", "äºˆæ¸¬4"]))
    else:
        st.warning("æ¡ä»¶ã«åˆè‡´ã™ã‚‹äºˆæ¸¬ãŒç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")