import requests
from bs4 import BeautifulSoup
import pandas as pd
import os

# ãƒ­ãƒˆ6æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹é–¢æ•°
def scrape_loto6_latest():
    url = "https://takarakuji-loto.jp/tousenp.html"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, "html.parser")

    try:
        print("ğŸš€ ãƒ­ãƒˆ6æœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")

        # æœ€æ–°ã®æŠ½é¸æƒ…å ±ã‚’å–å¾—
        draw_info = soup.find("div", class_="lb bold text16 font1")
        if draw_info is None:
            raise ValueError("âŒ æŠ½é¸æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚HTMLæ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        draw_text = draw_info.text.strip()

        draw_parts = draw_text.split()
        if len(draw_parts) < 5:
            raise ValueError(f"âŒ æŠ½é¸æƒ…å ±ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒäºˆæœŸã—ãªã„å½¢å¼ã§ã™: {draw_parts}")

        draw_number = draw_parts[0].replace("ç¬¬", "").replace("å›", "å›")
        draw_date = draw_parts[3] + " " + draw_parts[4]

        # å½“é¸ç•ªå·å–å¾—
        main_number_imgs = soup.select("table.rbox1 img")
        main_numbers = [img["alt"] for img in main_number_imgs[:6]]

        # ãƒœãƒ¼ãƒŠã‚¹æ•°å­—å–å¾—
        bonus_img = soup.select_one("table.rbox3 img")
        bonus_number = bonus_img["alt"] if bonus_img else "æœªå–å¾—"

        # ã‚­ãƒ£ãƒªãƒ¼ã‚ªãƒ¼ãƒãƒ¼å–å¾—
        carry_over = "0å††"
        carry_over_rows = soup.select("table.tb1 tr")
        for row in carry_over_rows:
            if "ã‚­ãƒ£ãƒªãƒ¼ã‚ªãƒ¼ãƒãƒ¼" in row.text:
                tds = row.find_all("td")
                if len(tds) >= 2:
                    carry_over = tds[1].text.strip()
                    break

        # è³é‡‘æƒ…å ±å–å¾—
        prize_rows = soup.select("table.tb1 tr")[1:6]  # 1ç­‰ã‹ã‚‰5ç­‰ã¾ã§
        prize_data = []
        for row in prize_rows:
            cols = row.find_all("td")
            if len(cols) == 4:
                grade = cols[0].text.strip()
                winners = cols[1].text.strip()
                amount = cols[2].text.strip()
                prize_data.append([grade, winners, amount])

        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ‘ã‚¹
        data_dir = "/Users/naokinishiyama/loto-prediction-app/data"
        os.makedirs(data_dir, exist_ok=True)

        # æœ€æ–°å½“é¸ç•ªå·CSVä¿å­˜ï¼ˆä¸Šæ›¸ããƒ¢ãƒ¼ãƒ‰ï¼‰
        latest_csv_path = os.path.join(data_dir, "loto6_latest.csv")
        latest_df = pd.DataFrame({
            "å›å·": [draw_number],
            "æŠ½ã›ã‚“æ—¥": [draw_date],
            "æœ¬æ•°å­—": [" ".join(main_numbers)],
            "ãƒœãƒ¼ãƒŠã‚¹æ•°å­—": [bonus_number],
            "ã‚­ãƒ£ãƒªãƒ¼ã‚ªãƒ¼ãƒãƒ¼": [carry_over]
        })
        latest_df.to_csv(latest_csv_path, index=False, encoding="utf-8-sig", mode="w")

        # è³é‡‘æƒ…å ±CSVä¿å­˜
        prize_csv_path = os.path.join(data_dir, "loto6_prizes.csv")
        prize_df = pd.DataFrame(prize_data, columns=["ç­‰ç´š", "å£æ•°", "å½“é¸é‡‘é¡"])
        prize_df["ã‚­ãƒ£ãƒªãƒ¼ã‚ªãƒ¼ãƒãƒ¼"] = carry_over  # ã‚­ãƒ£ãƒªãƒ¼ã‚ªãƒ¼ãƒãƒ¼ã‚’è¿½åŠ 
        prize_df.to_csv(prize_csv_path, index=False, encoding="utf-8-sig", mode="w")

        # ã‚­ãƒ£ãƒªãƒ¼ã‚ªãƒ¼ãƒãƒ¼æƒ…å ±CSVä¿å­˜
        carryover_csv_path = os.path.join(data_dir, "loto6_carryover.csv")
        carry_over_df = pd.DataFrame({"ã‚­ãƒ£ãƒªãƒ¼ã‚ªãƒ¼ãƒãƒ¼": [carry_over]})
        carry_over_df.to_csv(carryover_csv_path, index=False, encoding="utf-8-sig", mode="w")

        print("ğŸ¯ ãƒ­ãƒˆ6æœ€æ–°å½“é¸ç•ªå·ã€è³é‡‘æƒ…å ±ã€ã‚­ãƒ£ãƒªãƒ¼ã‚ªãƒ¼ãƒãƒ¼ã‚’ 'data/' ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã—ã¾ã—ãŸã€‚âœ…")

        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜å¾Œã«å³ç¢ºèª
        print("\nğŸ“Š æœ€æ–°ã®å½“é¸ç•ªå·:")
        print(pd.read_csv(latest_csv_path, encoding="utf-8").head())

    except Exception as e:
        print(f"âŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")

# å®Ÿè¡Œéƒ¨åˆ†
if __name__ == "__main__":
    scrape_loto6_latest()